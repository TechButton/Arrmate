# Arrmate Configuration
# Copy this file to .env and fill in your values

# Application Settings
APP_NAME=Arrmate
LOG_LEVEL=INFO
API_HOST=0.0.0.0
API_PORT=8000

# LLM Provider Configuration
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama Settings (default provider)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# OpenAI Settings
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_BASE_URL=  # Optional: for custom endpoints

# Anthropic Settings
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Sonarr Configuration
# SONARR_URL=http://localhost:8989
# SONARR_API_KEY=your-sonarr-api-key

# Radarr Configuration
# RADARR_URL=http://localhost:7878
# RADARR_API_KEY=your-radarr-api-key

# Lidarr Configuration
# LIDARR_URL=http://localhost:8686
# LIDARR_API_KEY=your-lidarr-api-key

# Docker Service Discovery
# DOCKER_NETWORK=media-network
ENABLE_SERVICE_DISCOVERY=true

# Notes:
# - For Docker deployment, use container names instead of localhost
#   Example: SONARR_URL=http://sonarr:8989
# - API keys can be found in each service's Settings > General > Security
# - Service discovery will attempt to auto-detect services on the Docker network
