# Local development .env example
# Copy this to .env for local testing

# Application Settings
LOG_LEVEL=DEBUG
API_HOST=0.0.0.0
API_PORT=8000

# LLM Provider - Use Ollama for local development
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# Or use OpenAI
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4-turbo-preview

# Or use Anthropic
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Sonarr Configuration
# Change localhost to actual hostname/IP if running remotely
SONARR_URL=http://localhost:8989
SONARR_API_KEY=your-sonarr-api-key-here

# Radarr Configuration
RADARR_URL=http://localhost:7878
RADARR_API_KEY=your-radarr-api-key-here

# Lidarr Configuration (optional)
# LIDARR_URL=http://localhost:8686
# LIDARR_API_KEY=your-lidarr-api-key-here

# Service Discovery
ENABLE_SERVICE_DISCOVERY=true
